#!/bin/bash

#SBATCH --job-name=MLPerf21-dlrm
#SBATCH --ntasks-per-node=8
#SBATCH --ntasks-per-socket=4
#SBATCH --cpus-per-task=8
#SBATCH --partition=champollion
#SBATCH --nodelist=o186i[222-223]
#SBATCH --exclusive

set -euxo pipefail

# Vars without defaults
: "${DGXSYSTEM:?DGXSYSTEM not set}"
: "${CONT:?CONT not set}"

export LOGDIR=${curDir}/logs/${SLURM_JOB_ID}

export MOUNTS="/apps:/apps,/nfs:/nfs,/tmp:/opt/hpcx/nccl_rdma_sharp_plugin,${SCRIPTS}:/workspace/dlrm,${DATADIR}:/raid/datasets/criteo/mlperf/40m.limit_preshuffled,${LOGDIR}:${LOGDIR}"

# Vars with defaults
: "${NEXP:=10}"
: "${DATESTAMP:=$(date +'%y%m%d%H%M%S%N')}"
: "${CLEAR_CACHES:=1}"
: "${API_LOG_DIR:=./api_logs}" # apiLog.sh output dir
: "${API_LOGGING:=0}"
: "${MOUNTS:='/raid/datasets:/raid/datasets,/gpfs/fs1:/gpfs/fs1'}"
: "${LOGDIR:=./results}"
if [ "${API_LOGGING:-}" -eq 1 ]; then
    MOUNTS="${MOUNTS},${API_LOG_DIR}:/logs"
fi

# monitoring RAPL and NVIDI-SMI
srun --overlap -l -n${SLURM_JOB_NUM_NODES} bash -c 'echo -n "Creating directory at " && hostname && pwd && mkdir -p ${LOGDIR}/$(hostname)/'
srun --overlap -l -n${SLURM_JOB_NUM_NODES} bash -c 'echo -n "Starting energy monitoring of ilo in " && hostname && bash ./hugectr/get_power.sh ${LOGDIR}/$(hostname)/ilo_power.csv' &
srun --overlap -l -n${SLURM_JOB_NUM_NODES} bash -c 'echo -n "Starting energy monitoring of RAPL and nvidia-smi in " && hostname && ./hugectr/nvml_sensor --result-dir ${LOGDIR}/$(hostname)/ --period-seconds 0.5' &

export NCCL_COLLNET_ENABLE=0

echo "Using SCRIPTS as ${SCRIPTS} , DATADIR as ${DATADIR} , LOGDIR as ${LOGDIR} with ${_config_file} file with mount=${MOUNTS}"

# make sure the results directory exists on the host
mkdir --parents "${LOGDIR}"

# Other vars
readonly _logfile_base="${LOGDIR}/${DATESTAMP}"
readonly _cont_name=dlrm

# Setup container
srun  --overlap --ntasks="${SLURM_JOB_NUM_NODES}" --container-image="${CONT}" --container-mounts="${MOUNTS}" --container-name="${_cont_name}" true

# Run experiments
for _experiment_index in $(seq -w 1 "${NEXP}"); do
    (
        echo "Sleeping before trial ${_experiment_index} of ${NEXP}"
        sleep 30
        echo "Beginning trial ${_experiment_index} of ${NEXP}"
        echo ":::DLPAL ${CONT} ${SLURM_JOB_ID} ${SLURM_JOB_NUM_NODES} ${SLURM_JOB_NODELIST}"
        if [[ $CLEAR_CACHES == 1 ]]; then
            srun --ntasks="${SLURM_JOB_NUM_NODES}" --container-mounts="${MOUNTS}"  bash -c "echo -n 'Clearing cache on ' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3"
            srun --ntasks="${SLURM_JOB_NUM_NODES}" --container-mounts="${MOUNTS}" --container-name="${_cont_name}" python3 /workspace/dlrm/drop.py
        fi
        echo "Beginning trial ${_experiment_index} of ${NEXP}"
        #srun --mpi=pmix --ntasks="${SLURM_JOB_NUM_NODES}" --ntasks-per-node=1 \
        srun   --overlap --mpi=pmix_v3 --ntasks="${SLURM_JOB_NUM_NODES}" --ntasks-per-node=1 \
             --container-name="${_cont_name}" --container-mounts="${MOUNTS}" \
             ${LOGGER:-} ./run_and_time.sh
        echo "Sleeping after trial ${_experiment_index} of ${NEXP} finished."
        sleep 30
    ) |& tee "${_logfile_base}_raw_${_experiment_index}.log"

    # Sorting the MLPerf compliance logs by timestamps
    cat "${_logfile_base}_raw_${_experiment_index}.log" | grep ":::.L..." | sort -k5 -n -s | tee "${_logfile_base}_${_experiment_index}.log"
done
